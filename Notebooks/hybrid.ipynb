{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d377e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#number of gpus available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e7140e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core scientific stack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep learning framework \n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.initializers import HeUniform\n",
    "from keras.models import load_model\n",
    "from keras import activations\n",
    "\n",
    "# Evaluation tools\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c0842e",
   "metadata": {},
   "source": [
    "**Load The Preprocessed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5419e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"/mnt/g/which one is it/data/GTSRB/processed/X_train.npy\", allow_pickle=True)\n",
    "y_train = np.load(\"/mnt/g/which one is it/data/GTSRB/processed/y_train.npy\", allow_pickle=True)\n",
    "X_val   = np.load(\"/mnt/g/which one is it/data/GTSRB/processed/X_val.npy\", allow_pickle=True)\n",
    "y_val   = np.load(\"/mnt/g/which one is it/data/GTSRB/processed/y_val.npy\", allow_pickle=True)\n",
    "X_test  = np.load(\"/mnt/g/which one is it/data/GTSRB/processed/X_test.npy\", allow_pickle=True)\n",
    "y_test  = np.load(\"/mnt/g/which one is it/data/GTSRB/processed/y_test.npy\", allow_pickle=True)\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:\", X_val.shape, y_val.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0640ed0d",
   "metadata": {},
   "source": [
    "**Random Seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "396a6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "import random\n",
    "seed_value = 7331\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928115cd",
   "metadata": {},
   "source": [
    "**Model Path and Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae36e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_path = '/mnt/g/which one is it/models/best_model.keras'\n",
    "cnn_model = load_model(keras_model_path)\n",
    "cnn_model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ead5ade",
   "metadata": {},
   "source": [
    "**Feature Layer Name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c2f693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer_name = 'batch_normalization_4'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ffae6",
   "metadata": {},
   "source": [
    "**Custom positional embedding layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52039737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional embedding that Keras can track\n",
    "@keras.utils.register_keras_serializable(package=\"Custom\", name=\"AddPositionEmbedding\")\n",
    "class AddPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, num_patches, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_patches = num_patches\n",
    "        self.embed_dim   = embed_dim\n",
    "        self.pos = self.add_weight(\n",
    "            name=\"pos_embedding\",\n",
    "            shape=(1, num_patches, embed_dim),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True)\n",
    "\n",
    "    def call(self, tokens):\n",
    "        return tokens + self.pos\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_patches\": self.num_patches,\n",
    "            \"embed_dim\":   self.embed_dim,\n",
    "        })\n",
    "        return {**config}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9fe678",
   "metadata": {},
   "source": [
    "**SwiGLU Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.utils.register_keras_serializable(package=\"Custom\", name=\"SwiGLU\")       \n",
    "class SwiGLULayer(layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.dense_gate = layers.Dense(units, name=\"dense_gate\")\n",
    "        self.dense_linear = layers.Dense(units, name=\"dense_linear\")\n",
    "        \n",
    "    def call(self, x):\n",
    "        # Apply the first linear transformation and the sigmoid linear unit (SiLU) activation\n",
    "        gate = self.dense_gate(x)\n",
    "        activated_gate = activations.silu(gate)\n",
    "        \n",
    "        # Apply the second linear transformation\n",
    "        linear = self.dense_linear(x)\n",
    "        \n",
    "        # Element-wise multiplication of the activated gate and the linear output\n",
    "        return activated_gate * linear\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"units\": self.units,\n",
    "        })\n",
    "        return {**config}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3082ce",
   "metadata": {},
   "source": [
    "**Transformer block implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fab65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Transformer encoder block\n",
    "@keras.utils.register_keras_serializable(package=\"Custom\", name=\"TransformerBlock\")\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ffn_dim, rate=0.1 ,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = SwiGLULayer(units=embed_dim)\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        self.ffn_dim = ffn_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"ffn_dim\": self.ffn_dim,\n",
    "            \"rate\": self.rate,\n",
    "        })\n",
    "        return {**config}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61757f2c",
   "metadata": {},
   "source": [
    " **Hybrid model builder function using QAT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20c56158",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "def build_cnn_vit_hybrid(\n",
    "        cnn_model,\n",
    "        feature_layer_name,\n",
    "        num_transformer_layers=3,\n",
    "        num_heads=8,\n",
    "        mlp_dim=1024,\n",
    "        num_classes=43):\n",
    "    # 1. Freeze or fine-tune the CNN as you prefer\n",
    "    cnn_model.trainable = True      \n",
    "    \n",
    "    # 2. Feature extractor up to the chosen layer\n",
    "    features = cnn_model.get_layer(feature_layer_name).output\n",
    "    H, W, C = features.shape[1], features.shape[2], features.shape[3]\n",
    "    \n",
    "    # 3. Flatten spatial grid → tokens  &  add positional encoding\n",
    "    x = layers.Reshape((H * W, C))(features) \n",
    "    x = AddPositionEmbedding(H * W, C)(x)\n",
    "\n",
    "    # 4. Stack ViT encoder blocks\n",
    "    for _ in range(num_transformer_layers):\n",
    "        x = TransformerBlock(C, num_heads, mlp_dim)(x)\n",
    "\n",
    "    # 5. Token pooling & classification head\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(cnn_model.layers[0].input, outputs, name=\"CNN_ViT_hybrid\")\n",
    "\n",
    "def create_quant_aware_hybrid_model(cnn_model, feature_layer_name):\n",
    "    quantize_model = tfmot.quantization.keras.quantize_model\n",
    "    q_aware_model = quantize_model(build_cnn_vit_hybrid(cnn_model, feature_layer_name))\n",
    "    return q_aware_model    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169556d",
   "metadata": {},
   "source": [
    "**Data Generator and Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a3ed5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "transform = A.Compose([\n",
    "    # Standard geometric transformations\n",
    "    A.Affine(\n",
    "        translate_percent=(-0.1, 0.1), # Shifts the image up to 10%\n",
    "        scale=(0.85, 1.15),           # Zooms in/out by 15%\n",
    "        rotate=(-15, 15),             # Rotates the image up to 15 degrees\n",
    "        p=0.75\n",
    "    ),\n",
    "    A.Perspective(scale=(0.05, 0.1), p=0.2),\n",
    "\n",
    "    # Image quality and noise simulations\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(p=0.4),\n",
    "        A.MotionBlur(blur_limit=(3, 7)),\n",
    "    ], p=0.4),\n",
    "\n",
    "    # Color and lighting variations\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n",
    "        A.RandomGamma(gamma_limit=(80, 120)),\n",
    "        A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10),\n",
    "    ], p=0.5),\n",
    "\n",
    "    # Advanced simulations of real-world conditions\n",
    "    A.OneOf([\n",
    "        A.RandomFog(fog_coef_range=(0.1, 0.3), p=1),\n",
    "        A.RandomRain(drop_length=15, drop_width=1, blur_value=3, p=1),\n",
    "        A.RandomSunFlare(p=1),\n",
    "    ], p=0.2),\n",
    "\n",
    "    # Occlusion simulation\n",
    "    A.CoarseDropout(\n",
    "        num_holes_range=(1, 5),          \n",
    "        hole_height_range=(0.01, 0.03),  \n",
    "        hole_width_range=(0.01, 0.03),   \n",
    "        fill=0,                    \n",
    "        p=0.1\n",
    "    ),\n",
    "])\n",
    "\n",
    "\n",
    "def augment_generator(X, y, batch_size=32):\n",
    "    n = len(X)\n",
    "    while True:\n",
    "        # Shuffle full dataset once per epoch\n",
    "        indices = np.random.permutation(n)\n",
    "        for i in range(0, n, batch_size):\n",
    "            batch_idx = indices[i:i+batch_size]\n",
    "            X_batch, y_batch = [], []\n",
    "            for j in batch_idx:\n",
    "                augmented = transform(image=X[j])[\"image\"]\n",
    "                X_batch.append(augmented)\n",
    "                y_batch.append(y[j])\n",
    "            yield np.array(X_batch), np.array(y_batch)\n",
    "\n",
    "\n",
    "train_gen = augment_generator(X_train, y_train, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a9cfb5",
   "metadata": {},
   "source": [
    "**Architecture and compile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a564d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_aware_model = build_cnn_vit_hybrid(\n",
    "        cnn_model,\n",
    "        feature_layer_name=feature_layer_name,\n",
    "        num_transformer_layers=3,\n",
    "        num_heads=8,\n",
    "        mlp_dim=1024,\n",
    "        num_classes=43)\n",
    "\n",
    "q_aware_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=6,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='CNN_ViT_hybrid.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dac4eb5",
   "metadata": {},
   "source": [
    "**Model Shape Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a80948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure end-to-end shapes line up\n",
    "dummy = tf.random.normal([1, 80, 80, 3])\n",
    "pred  = q_aware_model(dummy)\n",
    "print(\"Logits shape:\", pred.shape)   # should be (1, num_classes)\n",
    "# Expected output: Logits shape: (1, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a07424",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd5a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = q_aware_model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(X_train) // 16,\n",
    "    batch_size=16,\n",
    "    epochs=50,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop, checkpoint, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928e4f7c",
   "metadata": {},
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec328e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = q_aware_model.evaluate(X_test, y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f035497",
   "metadata": {},
   "source": [
    "**Plot Loss and Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5a30a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdbec6f",
   "metadata": {},
   "source": [
    "**Classification-Report and Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb9277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3️⃣ Confusion Matrix\n",
    "y_pred = q_aware_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=np.unique(y_true), yticklabels=np.unique(y_true))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 4️⃣ Classification Report\n",
    "report = classification_report(y_true, y_pred_classes, digits=3)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aad2f7",
   "metadata": {},
   "source": [
    "**ROC & AUC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8982ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_dict = {}\n",
    "# 5️⃣ ROC Curves and AUC\n",
    "for i in range(43):\n",
    "    fpr, tpr, _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_auc_dict[i] = roc_auc\n",
    "\n",
    "    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880a06b8",
   "metadata": {},
   "source": [
    "**Training Summary Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a103170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summary = {\n",
    "    \"Dataset\": [\"Training\", \"Validation\", \"Test\"],\n",
    "    \"Accuracy\": [\n",
    "        history.history['accuracy'][-1],      # last training acc\n",
    "        history.history['val_accuracy'][-1],  # last val acc\n",
    "        test_acc                               # from model.evaluate()\n",
    "    ],\n",
    "    \"Loss\": [\n",
    "        history.history['loss'][-1],          # last training loss\n",
    "        history.history['val_loss'][-1],      # last val loss\n",
    "        test_loss                              # from model.evaluate()\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_summary = pd.DataFrame(summary)\n",
    "print(df_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4852282",
   "metadata": {},
   "source": [
    "**Results Combined**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# --- Load data ---\n",
    "history_dict = history.history  # from model.fit()\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "y_val_pred = np.argmax(q_aware_model.predict(X_val), axis=1)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val_true, y_val_pred, labels=range(43))\n",
    "\n",
    "# Class distribution\n",
    "y_train_labels = np.argmax(y_train, axis=1)\n",
    "y_val_labels   = np.argmax(y_val, axis=1)\n",
    "y_test_labels  = np.argmax(y_test, axis=1)\n",
    "all_labels = np.concatenate([y_train_labels, y_val_labels, y_test_labels])\n",
    "counts = np.bincount(all_labels, minlength=43)\n",
    "\n",
    "# --- Plot ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22,6))\n",
    "\n",
    "# 1. Training curves\n",
    "axes[0].plot(history_dict[\"accuracy\"], label=\"Train Acc\")\n",
    "axes[0].plot(history_dict[\"val_accuracy\"], label=\"Val Acc\")\n",
    "axes[0].set_title(\"Training/Validation Accuracy\")\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Accuracy\")\n",
    "axes[0].legend()\n",
    "\n",
    "# 2. Confusion matrix (heatmap)\n",
    "sns.heatmap(cm, ax=axes[1], cmap=\"Blues\", cbar=False)\n",
    "axes[1].set_title(\"Confusion Matrix (Validation)\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"True\")\n",
    "\n",
    "# 3. Class distribution\n",
    "axes[2].bar(range(43), counts, color=\"steelblue\")\n",
    "axes[2].set_title(\"Samples per Class (Train+Val+Test)\")\n",
    "axes[2].set_xlabel(\"Class ID\")\n",
    "axes[2].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
