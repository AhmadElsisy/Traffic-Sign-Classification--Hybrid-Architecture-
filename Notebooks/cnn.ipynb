{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650de157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#number of gpus available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9688a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core scientific stack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep learning framework \n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Evaluation tools\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f28a1",
   "metadata": {},
   "source": [
    "**Load the Saved Preprocessed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f241bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"/mnt/g/which one is it/data/GTSRB/processed/X_train.npy\", allow_pickle=True)\n",
    "y_train = np.load(\"/mnt/g/which one is it/data/GTSRB/processed/y_train.npy\", allow_pickle=True)\n",
    "X_val   = np.load(\"/mnt/g/which one is it/data/GTSRB/processed/X_val.npy\", allow_pickle=True)\n",
    "y_val   = np.load(\"/mnt/g/which one is it/data/GTSRB/processed/y_val.npy\", allow_pickle=True)\n",
    "X_test  = np.load(\"/mnt/g/which one is it/data/GTSRB/processed/X_test.npy\", allow_pickle=True)\n",
    "y_test  = np.load(\"/mnt/g/which one is it/data/GTSRB/processed/y_test.npy\", allow_pickle=True)\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:\", X_val.shape, y_val.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983fc86b",
   "metadata": {},
   "source": [
    "**Define augmentation pipeline + generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f646eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "transform = A.Compose([\n",
    "    # Standard geometric transformations\n",
    "    A.Affine(\n",
    "        translate_percent=(-0.1, 0.1), # Shifts the image up to 10%\n",
    "        scale=(0.85, 1.15),           # Zooms in/out by 15%\n",
    "        rotate=(-15, 15),             # Rotates the image up to 15 degrees\n",
    "        p=0.75\n",
    "    ),\n",
    "    A.Perspective(scale=(0.05, 0.1), p=0.2),\n",
    "\n",
    "    # Image quality and noise simulations\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(p=0.4),\n",
    "        A.MotionBlur(blur_limit=(3, 7)),\n",
    "    ], p=0.4),\n",
    "\n",
    "    # Color and lighting variations\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n",
    "        A.RandomGamma(gamma_limit=(80, 120)),\n",
    "        A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10),\n",
    "    ], p=0.5),\n",
    "\n",
    "    # Advanced simulations of real-world conditions\n",
    "    A.OneOf([\n",
    "        A.RandomFog(fog_coef_range=(0.1, 0.3), p=1),\n",
    "        A.RandomRain(drop_length=15, drop_width=1, blur_value=3, p=1),\n",
    "        A.RandomSunFlare(p=1),\n",
    "    ], p=0.2),\n",
    "\n",
    "    # Occlusion simulation\n",
    "    A.CoarseDropout(\n",
    "        num_holes_range=(1, 5),          \n",
    "        hole_height_range=(0.01, 0.03),  \n",
    "        hole_width_range=(0.01, 0.03),   \n",
    "        fill=0,                    \n",
    "        p=0.1\n",
    "    ),\n",
    "])\n",
    "\n",
    "\n",
    "def augment_generator(X, y, batch_size=32):\n",
    "    n = len(X)\n",
    "    while True:\n",
    "        # Shuffle full dataset once per epoch\n",
    "        indices = np.random.permutation(n)\n",
    "        for i in range(0, n, batch_size):\n",
    "            batch_idx = indices[i:i+batch_size]\n",
    "            X_batch, y_batch = [], []\n",
    "            for j in batch_idx:\n",
    "                augmented = transform(image=X[j])[\"image\"]\n",
    "                X_batch.append(augmented)\n",
    "                y_batch.append(y[j])\n",
    "            yield np.array(X_batch), np.array(y_batch)\n",
    "\n",
    "\n",
    "train_gen = augment_generator(X_train, y_train, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afac355b",
   "metadata": {},
   "source": [
    "**Create The CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cac4416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# Set the global policy to use mixed precision\n",
    "keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5f8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model():\n",
    "\n",
    "    model = Sequential([\n",
    "        \n",
    "        keras.layers.Input(shape=(80,80,3)),\n",
    "        \n",
    "\n",
    "        # Block1\n",
    "        keras.layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPooling2D((2,2)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "\n",
    "        # Block2\n",
    "        keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPooling2D((2,2)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "\n",
    "        # Block3\n",
    "        keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPooling2D((2,2)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "         # Block3\n",
    "        keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPooling2D((2,2)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "        # Block4\n",
    "        keras.layers.Conv2D(512, (3,3), activation='relu', padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPooling2D((2,2)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "\n",
    "        # GAP + FC\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "\n",
    "        # Output\n",
    "        keras.layers.Dense(43, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f086bf",
   "metadata": {},
   "source": [
    "**Compile The model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f98e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv_model()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=6,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa23390",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7702e232",
   "metadata": {},
   "source": [
    "**Train The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c2fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(X_train) // 16,\n",
    "    batch_size=16,\n",
    "    epochs=50,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop, checkpoint, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38924bd4",
   "metadata": {},
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b94a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c11bce6",
   "metadata": {},
   "source": [
    "**Plotting Loss and Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076dac8",
   "metadata": {},
   "source": [
    "**Classification-Report and Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6141ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3️⃣ Confusion Matrix\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=np.unique(y_true), yticklabels=np.unique(y_true))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 4️⃣ Classification Report\n",
    "report = classification_report(y_true, y_pred_classes, digits=3)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62219b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_dict = {}\n",
    "# 5️⃣ ROC Curves and AUC\n",
    "for i in range(43):\n",
    "    fpr, tpr, _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_auc_dict[i] = roc_auc\n",
    "\n",
    "    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb77c6d9",
   "metadata": {},
   "source": [
    "**Training Summary Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1274d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summary = {\n",
    "    \"Dataset\": [\"Training\", \"Validation\", \"Test\"],\n",
    "    \"Accuracy\": [\n",
    "        history.history['accuracy'][-1],      # last training acc\n",
    "        history.history['val_accuracy'][-1],  # last val acc\n",
    "        test_acc                               # from model.evaluate()\n",
    "    ],\n",
    "    \"Loss\": [\n",
    "        history.history['loss'][-1],          # last training loss\n",
    "        history.history['val_loss'][-1],      # last val loss\n",
    "        test_loss                              # from model.evaluate()\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_summary = pd.DataFrame(summary)\n",
    "print(df_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa5b7ec",
   "metadata": {},
   "source": [
    "**Per-Class Data Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load your train/val labels (one-hot → convert back to class IDs)\n",
    "y_train_labels = np.argmax(np.load(\"/mnt/g/which one is it/data/GTSRB/processed/y_train.npy\"), axis=1)\n",
    "y_val_labels   = np.argmax(np.load(\"/mnt/g/which one is it/data/GTSRB/processed/y_val.npy\"), axis=1)\n",
    "y_test_labels  = np.argmax(np.load(\"/mnt/g/which one is it/data/GTSRB/processed/y_test.npy\"), axis=1)\n",
    "\n",
    "# Combine for a full picture\n",
    "all_labels = np.concatenate([y_train_labels, y_val_labels, y_test_labels])\n",
    "\n",
    "# Count samples per class\n",
    "counts = np.bincount(all_labels, minlength=43)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.bar(range(43), counts, color=\"steelblue\")\n",
    "plt.title(\"GTSRB Dataset – Samples per Class\", fontsize=14)\n",
    "plt.xlabel(\"Class ID\", fontsize=12)\n",
    "plt.ylabel(\"Number of Images\", fontsize=12)\n",
    "plt.xticks(range(43))\n",
    "plt.show()\n",
    "\n",
    "print(\"Class distribution:\\n\", counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f699e5",
   "metadata": {},
   "source": [
    "As the figure shows, some classes have >2000 images while others have <300. This imbalance explains why recall is lower for rare classes in the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc63691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# --- Load data ---\n",
    "history_dict = history.history  # from model.fit()\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "y_val_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val_true, y_val_pred, labels=range(43))\n",
    "\n",
    "# Class distribution\n",
    "y_train_labels = np.argmax(y_train, axis=1)\n",
    "y_val_labels   = np.argmax(y_val, axis=1)\n",
    "y_test_labels  = np.argmax(y_test, axis=1)\n",
    "all_labels = np.concatenate([y_train_labels, y_val_labels, y_test_labels])\n",
    "counts = np.bincount(all_labels, minlength=43)\n",
    "\n",
    "# --- Plot ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22,6))\n",
    "\n",
    "# 1. Training curves\n",
    "axes[0].plot(history_dict[\"accuracy\"], label=\"Train Acc\")\n",
    "axes[0].plot(history_dict[\"val_accuracy\"], label=\"Val Acc\")\n",
    "axes[0].set_title(\"Training/Validation Accuracy\")\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Accuracy\")\n",
    "axes[0].legend()\n",
    "\n",
    "# 2. Confusion matrix (heatmap)\n",
    "sns.heatmap(cm, ax=axes[1], cmap=\"Blues\", cbar=False)\n",
    "axes[1].set_title(\"Confusion Matrix (Validation)\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"True\")\n",
    "\n",
    "# 3. Class distribution\n",
    "axes[2].bar(range(43), counts, color=\"steelblue\")\n",
    "axes[2].set_title(\"Samples per Class (Train+Val+Test)\")\n",
    "axes[2].set_xlabel(\"Class ID\")\n",
    "axes[2].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
